{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество элементов в массиве: 532\n",
      "Количество элементов с videoPlayCount больше 100000: 232\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Открываем файл и загружаем данные\n",
    "with open('db/12/potok_lifeplus_apify_20241227_001202.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Предполагаем, что данные находятся в корневом массиве\n",
    "element_count = len(data)\n",
    "print(f'Количество элементов в массиве: {element_count}')\n",
    "\n",
    "# Фильтруем элементы с videoPlayCount > 100000\n",
    "filtered_count = sum(1 for item in data if item.get('videoPlayCount') > 100000)\n",
    "\n",
    "print(f'Количество элементов с videoPlayCount больше 100000: {filtered_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество элементов в массиве \"transcriptions\": 216\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Открываем файл и загружаем данные\n",
    "with open('db/12/potok_lifeplus_transcriptions_20241227_001202.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Предполагаем, что данные находятся в корневом словаре\n",
    "# Проверяем наличие ключа \"transcriptions\" и считаем количество элементов\n",
    "if 'transcriptions' in data:\n",
    "    transcription_count = len(data['transcriptions'])\n",
    "else:\n",
    "    transcription_count = 0\n",
    "\n",
    "print(f'Количество элементов в массиве \"transcriptions\": {transcription_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Открываем файл и загружаем данные\n",
    "with open('db/12/potok_lifeplus_apify_20241227_001202.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Предполагаем, что данные находятся в корневом массиве\n",
    "element_count = len(data)\n",
    "print(f'Количество элементов в массиве: {element_count}')\n",
    "\n",
    "# Извлекаем уникальные значения 'ownerUsername'\n",
    "unique_owner_usernames = set(item['inputUrl'] for item in data if 'inputUrl' in item)\n",
    "# Извлекаем username из каждой ссылки\n",
    "usernames = [link.split('/')[-1] for link in unique_owner_usernames]\n",
    "\n",
    "# Сортируем уникальные значения в алфавитном порядке\n",
    "sorted_usernames = sorted(usernames)\n",
    "\n",
    "# Выводим уникальные значения в столбик\n",
    "print('Уникальные значения ownerUsername в алфавитном порядке:')\n",
    "for username in sorted_usernames:\n",
    "    print(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = '''\n",
    "gastrosmile\n",
    "dr.shefova\n",
    "kpuctakl\n",
    "ankacheeta\n",
    "baranova__irina\n",
    "magerya_endocrinolog_\n",
    "doctor_polyanina\n",
    "doctorspiridonova\n",
    "dr_ryabichko.v\n",
    "doc_magomedova\n",
    "dr.narzs\n",
    "dr_masgutov_health\n",
    "regina_doctor\n",
    "katerina.novaya\n",
    "una.tuna\n",
    "cardiodok\n",
    "wellness.genetics\n",
    "nelly_petrosian\n",
    "diadoctor_lebedeva\n",
    "anyclass.faceonline\n",
    "doctor_komarovskiy\n",
    "doctor_belokon\n",
    "kronindoc\n",
    "dsemiryadov\n",
    "biouniqum\n",
    "dzari.alex\n",
    "tamilla_amirova\n",
    "dailyom\n",
    "the.holistic.psychologist\n",
    "theworkoutwitch_\n",
    "drmarkhyman\n",
    "thebraincoach\n",
    "thefoodbabe\n",
    "glucosegoddess\n",
    "foundmyfitness\n",
    "genuinely.healthy\n",
    "gutthrives\n",
    "drericberg\n",
    "gutelevate\n",
    "healthy.harbor\n",
    "jaymiemoran\n",
    "fitstars.ru\n",
    "doctor_zubareva\n",
    "fittrwithsquats\n",
    "fastingmd\n",
    "functionhealth\n",
    "dolphinine\n",
    "labifyhealth\n",
    "thewellnesswaylargo\n",
    "planetfitness\n",
    "myfitnesspal\n",
    "ouraring\n",
    "whoop\n",
    "calm\n",
    "betterme\n",
    "luke_coutinho\n",
    "somya_luhadia\n",
    "simrun.chopra\n",
    "soms_g\n",
    "jinals89\n",
    "satvicmovement\n",
    "nmamiagarwal\n",
    "rujuta.diwekar\n",
    "dt.lavleen\n",
    "coachshivangidesai'''\n",
    "\n",
    "# Разбиваем строки на список и сортируем\n",
    "sorted_values = sorted(old.strip().split('\\n'))\n",
    "\n",
    "# Выводим отсортированные значения\n",
    "for value in sorted_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 43.333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Задаем значения\n",
    "a = 2.71\n",
    "b = 1.94\n",
    "\n",
    "# Вычисляем среднее арифметическое\n",
    "average = (a + b) / 2\n",
    "\n",
    "# Умножаем на 200\n",
    "result = 13 * 200 / 60\n",
    "\n",
    "print(f'Результат: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Фильтрация завершена. Отфильтрованные данные сохранены в 'filtered_video_play_count.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Чтение существующего JSON файла\n",
    "with open('db/11/daria_koziakova_apify_20241227_225544.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Фильтрация данных\n",
    "filtered_data = [\n",
    "    item for item in data if 20000 <= item.get('videoPlayCount', 0) < 30000\n",
    "]\n",
    "\n",
    "# Запись отфильтрованных данных в новый JSON файл\n",
    "with open('db/11/daria_koziakova_apify_20241227_225544_20k-30k.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(filtered_data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"Фильтрация завершена. Отфильтрованные данные сохранены в 'filtered_video_play_count.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n",
      "6947\n",
      "27\n",
      "5212\n",
      "64\n",
      "584\n",
      "284\n",
      "1002\n",
      "148417\n",
      "59\n",
      "2524\n",
      "326\n",
      "2686\n",
      "191\n",
      "756\n",
      "75\n",
      "2204\n",
      "907\n",
      "666\n",
      "670\n",
      "11228\n",
      "69\n",
      "47\n",
      "454\n",
      "55\n",
      "-1\n",
      "1208\n",
      "35\n",
      "43\n",
      "220\n",
      "92\n",
      "20590\n",
      "2576\n",
      "1612\n",
      "3602\n",
      "728\n",
      "1505\n",
      "336\n",
      "372\n",
      "158\n",
      "447\n",
      "6531\n",
      "8\n",
      "1022\n",
      "40396\n",
      "12053\n",
      "130\n",
      "5714\n",
      "1490\n",
      "456\n",
      "588\n",
      "67\n",
      "62\n",
      "-1\n",
      "23591\n",
      "5198\n",
      "14\n",
      "2257\n",
      "141\n",
      "632\n",
      "3\n",
      "2951\n",
      "87803\n",
      "3051\n",
      "1668\n",
      "31\n",
      "-1\n",
      "1004\n",
      "1535\n",
      "5\n",
      "15284\n",
      "6119\n",
      "1758\n",
      "479\n",
      "7344\n",
      "9135\n",
      "229\n",
      "83\n",
      "14082\n",
      "151\n",
      "1505\n",
      "2055\n",
      "1018\n",
      "4387\n",
      "62\n",
      "30\n",
      "15514\n",
      "10452\n",
      "243\n",
      "4489\n",
      "9800\n",
      "237\n",
      "517\n",
      "587\n",
      "1027\n",
      "816\n",
      "468\n",
      "7789\n",
      "4011\n",
      "3181\n",
      "392\n",
      "5796\n",
      "1625\n",
      "1113\n",
      "22\n",
      "34785\n",
      "520\n",
      "7712\n",
      "278\n",
      "2576\n",
      "78\n",
      "222\n",
      "459\n",
      "1343\n",
      "2233\n",
      "-1\n",
      "19523\n",
      "19309\n",
      "4962\n",
      "32\n",
      "296\n",
      "1212\n",
      "666\n",
      "1086\n",
      "141\n",
      "31\n",
      "-1\n",
      "3996\n",
      "2847\n",
      "9757\n",
      "2756\n",
      "702\n",
      "253\n",
      "242\n",
      "137965\n",
      "8266\n",
      "-1\n",
      "1483\n",
      "1367\n",
      "321\n",
      "3701\n",
      "734\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Открываем файл и загружаем данные\n",
    "with open('db/manual/kumarsolo_result_20241231.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Проверяем, что данные являются массивом\n",
    "if isinstance(data, list):\n",
    "    # Выводим элементы массива в столбик\n",
    "    for item in data:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"Данные не являются массивом.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the lists into Python sets\n",
    "list1 = '''loewhaley\n",
    "matthgray\n",
    "corporatenatalie\n",
    "emily.the.recruiter\n",
    "sarajaneho\n",
    "wethinkdeeply\n",
    "avnibarman_\n",
    "vera_churina\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "wethinkdeeply\n",
    "sedakasparova\n",
    "avnibarman_\n",
    "matthgray\n",
    "corporatenatalie\n",
    "sarajaneho\n",
    "showschool.korolkov\n",
    "askvinh\n",
    "avnibarman_\n",
    "kenimilovanov\n",
    "loewhaley\n",
    "goodmorgantherapy\n",
    "corporatenatalie\n",
    "askvinh\n",
    "radislavgandapas\n",
    "sedakasparova\n",
    "showschool.korolkov\n",
    "showschool.korolkov\n",
    "corporatenatalie\n",
    "askvinh\n",
    "wethinkdeeply\n",
    "kenimilovanov\n",
    "avnibarman_\n",
    "corporatenatalie\n",
    "askvinh\n",
    "jefferson_fisher\n",
    "loewhaley\n",
    "corporatenatalie\n",
    "askvinh\n",
    "emily.the.recruiter\n",
    "loewhaley\n",
    "melissawoodtepperberg\n",
    "corporatenatalie\n",
    "askvinh\n",
    "jefferson_fisher\n",
    "loewhaley\n",
    "emily.the.recruiter\n",
    "melissawoodtepperberg\n",
    "corporatenatalie\n",
    "askvinh\n",
    "sedakasparova\n",
    "jefferson_fisher\n",
    "showschool.korolkov\n",
    "showschool.korolkov\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "sedakasparova\n",
    "kenimilovanov\n",
    "loewhaley\n",
    "emily.the.recruiter\n",
    "melissawoodtepperberg\n",
    "corporatenatalie\n",
    "askvinh\n",
    "kenimilovanov\n",
    "melissawoodtepperberg\n",
    "avnibarman_\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "askvinh\n",
    "sedakasparova\n",
    "kenimilovanov\n",
    "avnibarman_\n",
    "corporatenatalie\n",
    "reina.suichan\n",
    "askvinh\n",
    "kenimilovanov\n",
    "avnibarman_\n",
    "loewhaley\n",
    "goodmorgantherapy\n",
    "corporatenatalie\n",
    "itsaudreychow\n",
    "sedakasparova\n",
    "jefferson_fisher\n",
    "askvinh\n",
    "loewhaley\n",
    "matthgray\n",
    "emily.the.recruiter\n",
    "melissawoodtepperberg\n",
    "corporatenatalie\n",
    "kenimilovanov\n",
    "askvinh\n",
    "melissawoodtepperberg\n",
    "jefferson_fisher\n",
    "avnibarman_\n",
    "loewhaley\n",
    "corporatenatalie\n",
    "kenimilovanov\n",
    "melissawoodtepperberg\n",
    "jefferson_fisher\n",
    "loewhaley\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "askvinh\n",
    "itsaudreychow\n",
    "kenimilovanov\n",
    "jefferson_fisher\n",
    "loewhaley\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "melissawoodtepperberg\n",
    "askvinh\n",
    "kenimilovanov\n",
    "corporatenatalie\n",
    "askvinh\n",
    "avnibarman_\n",
    "emily.the.recruiter\n",
    "corporatenatalie\n",
    "melissawoodtepperberg\n",
    "reina.suichan\n",
    "askvinh\n",
    "itsaudreychow\n",
    "sedakasparova\n",
    "'''\n",
    "\n",
    "list2 = '''vera_churina\n",
    "hannagetshired\n",
    "itsaudreychow\n",
    "melissawoodtepperberg\n",
    "sedakasparova\n",
    "avnibarman_\n",
    "radislavgandapas\n",
    "showschool.korolkov\n",
    "loewhaley\n",
    "corporatenatalie\n",
    "jefferson_fisher\n",
    "emily.the.recruiter\n",
    "reina.suichan\n",
    "matthgray\n",
    "kenimilovanov\n",
    "wethinkdeeply\n",
    "goodmorgantherapy\n",
    "askvinh\n",
    "sarajaneho'''\n",
    "\n",
    "# Convert the lists into sets\n",
    "set1 = set(list1.splitlines())\n",
    "set2 = set(list2.splitlines())\n",
    "\n",
    "# Find elements in set1 that are not in set2\n",
    "missing_in_list2 = set1 - set2\n",
    "\n",
    "missing_in_list2\n",
    "#        \"inputUrl\": \"https://www.instagram.com/valerymis\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valerymis\n"
     ]
    }
   ],
   "source": [
    "data = [{\n",
    "        \"inputUrl\": \"https://www.instagram.com/valerymis\"}]\n",
    "for entry in data:\n",
    "    #это нужно, чтобы убрать сокриэйтеров рилса\n",
    "    username_real = entry.get('inputUrl').split('/')[-1]\n",
    "print(username_real)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Повтор для sandracreatess: старое значение 0, новое 0\n",
      "Повтор для ryanspenner.tv: старое значение 0, новое 0\n",
      "Повтор для mosseri: старое значение 2, новое 2\n",
      "Повтор для thecreative.social: старое значение 0, новое 0\n",
      "Сумма значений (sum_s): 217\n",
      "Сумма из словаря info1_dict (total_info1): 217\n",
      "Несчитанные строки: []\n"
     ]
    }
   ],
   "source": [
    "# информация1:\n",
    "info1 = '''stanforcreators;1\n",
    "kajabi;0\n",
    "kofi_button;0\n",
    "buymeacoffee;0\n",
    "uscreentv;0\n",
    "'''\n",
    "\n",
    "# Список ссылок относительно юзера:\n",
    "info2 = '''editorhardy\thttps://www.instagram.com/p/DDt_Iv0TDJg/\n",
    "theintrovertedattorney\thttps://www.instagram.com/p/DD7CVjOpG2t/\n",
    "justme.rod\thttps://www.instagram.com/p/DDsw2dkuvzF/\n",
    "ichvse\thttps://www.instagram.com/p/DDs1foUA0Wp/\n",
    "'''\n",
    "\n",
    "sum_s = 0\n",
    "info1_dict = {}\n",
    "processed_lines = set()\n",
    "missing_lines = []\n",
    "\n",
    "for line in info1.strip().split('\\n'):\n",
    "    parts = line.split(';') if ';' in line else line.split('\\t')\n",
    "    if len(parts) == 2:\n",
    "        username, count = parts[0].strip(), int(parts[1].strip())\n",
    "        if username in info1_dict:\n",
    "            print(f\"Повтор для {username}: старое значение {info1_dict[username]}, новое {count}\")\n",
    "        info1_dict[username] = info1_dict.get(username, 0) + count  # Суммируем значения для повторов\n",
    "        sum_s += count\n",
    "    else:\n",
    "        missing_lines.append(line)\n",
    "\n",
    "total_info1 = sum(info1_dict.values())\n",
    "print(f\"Сумма значений (sum_s): {sum_s}\")\n",
    "print(f\"Сумма из словаря info1_dict (total_info1): {total_info1}\")\n",
    "print(f\"Несчитанные строки: {missing_lines}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: Video, Shortcode:  DEGlApKyZij, Timestamp: 2024-12-28T00:59:23.000Z\n",
      "Type: Video, Shortcode:  DEHTRcTMqHh, Timestamp: 2024-12-28T07:46:23.000Z\n",
      "Type: Video, Shortcode:  DEHcIK5yJCH, Timestamp: 2024-12-28T09:01:55.000Z\n",
      "Type: Video, Shortcode:  DEHwxMrMfKy, Timestamp: 2024-12-28T12:01:46.000Z\n",
      "Type: Sidecar, Shortcode:  DEIEkCvztxL, Timestamp: 2024-12-28T14:54:04.000Z\n",
      "Type: Video, Shortcode:  DEIJJEozyhM, Timestamp: 2024-12-28T15:34:46.000Z\n",
      "Type: Video, Shortcode:  DEIWcyXvng0, Timestamp: 2024-12-28T17:30:00.000Z\n",
      "Type: Video, Shortcode:  DEJQwbmPskh, Timestamp: 2024-12-29T02:00:19.000Z\n",
      "Type: Video, Shortcode:  DEJvvaDMf4k, Timestamp: 2024-12-29T06:30:00.000Z\n",
      "Type: Video, Shortcode:  DEJ1nvbSWZ7, Timestamp: 2024-12-29T07:23:12.000Z\n",
      "Type: Video, Shortcode:  DEKa3kkBEjN, Timestamp: 2024-12-29T12:47:37.000Z\n",
      "Type: Video, Shortcode:  DEKf3BSs27q, Timestamp: 2024-12-29T13:32:53.000Z\n",
      "Type: Sidecar, Shortcode:  DEK23QRTUVn, Timestamp: 2024-12-29T16:52:05.000Z\n",
      "Type: Sidecar, Shortcode:  DELj1eTSZr8, Timestamp: 2024-12-29T23:25:03.000Z\n",
      "Type: Video, Shortcode:  DELug1tSaFe, Timestamp: 2024-12-30T00:58:48.000Z\n",
      "Type: Video, Shortcode:  DEMfAWCsQBf, Timestamp: 2024-12-30T08:02:14.000Z\n",
      "Type: Image, Shortcode:  DEMvw3NTqxZ, Timestamp: 2024-12-30T10:28:31.000Z\n",
      "Type: Video, Shortcode:  DEM9HMGywF9, Timestamp: 2024-12-30T12:30:31.000Z\n",
      "Type: Video, Shortcode:  DEM_VNYSo0K, Timestamp: 2024-12-30T12:45:16.000Z\n",
      "Type: Sidecar, Shortcode:  DEM_rIPtNb0, Timestamp: 2024-12-30T12:47:33.000Z\n",
      "Type: Video, Shortcode:  DENMllah2ai, Timestamp: 2024-12-30T14:42:23.000Z\n",
      "Type: Video, Shortcode:  DENfrfEO1uR, Timestamp: 2024-12-30T17:28:18.000Z\n",
      "Type: Video, Shortcode:  DENm5TEi4Pa, Timestamp: 2024-12-30T18:30:00.000Z\n",
      "Type: Video, Shortcode:  DEOesNSpEZF, Timestamp: 2024-12-31T02:38:34.000Z\n",
      "Type: Sidecar, Shortcode:  DEO0D5mTfzZ, Timestamp: 2024-12-31T05:44:33.000Z\n",
      "Type: Video, Shortcode:  DEQRiQsOG9O, Timestamp: 2024-12-31T19:22:07.000Z\n",
      "Type: Video, Shortcode:  DEQ4UMbRKz9, Timestamp: 2025-01-01T01:00:49.000Z\n",
      "Type: Video, Shortcode:  DERrArVxpmq, Timestamp: 2025-01-01T08:24:04.000Z\n",
      "Type: Video, Shortcode:  DERvCobRMXq, Timestamp: 2025-01-01T09:00:42.000Z\n",
      "Type: Video, Shortcode:  DERwPW6xvEd, Timestamp: 2025-01-01T09:09:56.000Z\n",
      "Type: Video, Shortcode:  DERwqeNxTWx, Timestamp: 2025-01-01T09:12:57.000Z\n",
      "Type: Video, Shortcode:  DESM0DMzcI3, Timestamp: 2025-01-01T13:19:41.000Z\n",
      "Type: Video, Shortcode:  DESRTUsBUFD, Timestamp: 2025-01-01T14:00:22.000Z\n",
      "Type: Video, Shortcode:  DESllofMCvC, Timestamp: 2025-01-01T16:55:27.000Z\n",
      "Локальные переменные: {\n",
      "    \"days\": 1,\n",
      "    \"range_days\": \"3-4\",\n",
      "    \"target_day\": \"2024-12-31 22:29:57.116155\",\n",
      "    \"start_of_day\": \"2024-12-28\",\n",
      "    \"end_of_day\": \"2024-12-29\",\n",
      "    \"start_range\": 3,\n",
      "    \"end_range\": 4\n",
      "}\n",
      "--------\n",
      "count of input items: 35\n",
      "-----\n",
      "2025-01-01\n",
      "2025-01-01\n",
      "2025-01-01\n",
      "2025-01-01\n",
      "2024-12-30\n",
      "2025-01-01\n",
      "2024-12-31\n",
      "2024-12-30\n",
      "2024-12-29\n",
      "2024-12-31\n",
      "2024-12-30\n",
      "2024-12-28\n",
      "2024-12-28\n",
      "2025-01-01\n",
      "2024-12-29\n",
      "2024-12-30\n",
      "2024-12-28\n",
      "2025-01-01\n",
      "2024-12-29\n",
      "2024-12-30\n",
      "2024-12-28\n",
      "2024-12-28\n",
      "2024-12-28\n",
      "2024-12-30\n",
      "2024-12-30\n",
      "2024-12-29\n",
      "2025-01-01\n",
      "2024-12-29\n",
      "Отфильтрованные рилсы:\n",
      "Shortcode: DEJQwbmPskh, Timestamp: 2024-12-29T02:00:19.000Z\n",
      "Shortcode: DEIWcyXvng0, Timestamp: 2024-12-28T17:30:00.000Z\n",
      "Shortcode: DEGlApKyZij, Timestamp: 2024-12-28T00:59:23.000Z\n",
      "Shortcode: DEKa3kkBEjN, Timestamp: 2024-12-29T12:47:37.000Z\n",
      "Shortcode: DEIJJEozyhM, Timestamp: 2024-12-28T15:34:46.000Z\n",
      "Shortcode: DEKf3BSs27q, Timestamp: 2024-12-29T13:32:53.000Z\n",
      "Shortcode: DEHwxMrMfKy, Timestamp: 2024-12-28T12:01:46.000Z\n",
      "Shortcode: DEHTRcTMqHh, Timestamp: 2024-12-28T07:46:23.000Z\n",
      "Shortcode: DEHcIK5yJCH, Timestamp: 2024-12-28T09:01:55.000Z\n",
      "Shortcode: DEJ1nvbSWZ7, Timestamp: 2024-12-29T07:23:12.000Z\n",
      "Shortcode: DEJvvaDMf4k, Timestamp: 2024-12-29T06:30:00.000Z\n"
     ]
    }
   ],
   "source": [
    "#testing day count for reels data filter\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Загрузка данных из нового файла\n",
    "try:\n",
    "    with open('db/manual/dataset_instagram-post-scraper_2025-01-01_21-04-37-484.json', 'r', encoding='utf-8') as file:\n",
    "        dataset_items = json.load(file)  # Загружаем данные в переменную dataset_items\n",
    "except FileNotFoundError:\n",
    "    print(\"Файл не найден. Проверьте путь к файлу.\")\n",
    "    dataset_items = []\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Ошибка при декодировании JSON. Проверьте содержимое файла.\")\n",
    "    dataset_items = []\n",
    "\n",
    "dataset_sorted = dataset_items\n",
    "# Фильтруем элементы без timestamp и сортируем по timestamp\n",
    "dataset_sorted = [item for item in dataset_sorted if 'timestamp' in item]\n",
    "dataset_sorted.sort(key=lambda x: datetime.strptime(x['timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "\n",
    "for item in dataset_sorted:\n",
    "    print(f\"Type: {item.get('type')}, Shortcode:  {item.get('shortCode')}, Timestamp: {item.get('timestamp')}\")\n",
    "\n",
    "reelsData = []  # Инициализация списка для хранения отфильтрованных данных\n",
    "\n",
    "def instagram_posts_scrapper(days=3, range_days=None):\n",
    "\n",
    "\n",
    "\n",
    "    # Рассчитываем целевые дни\n",
    "    target_day = datetime.now() - timedelta(days=days)\n",
    "    start_of_day = target_day.date()  # Получаем только дату\n",
    "    end_of_day = (target_day + timedelta(days=1)).date()  # Получаем только дату\n",
    "\n",
    "    # Если указан диапазон дней\n",
    "    if range_days:\n",
    "        start_range, end_range = map(int, range_days.split('-'))\n",
    "        start_of_day = (datetime.now() - timedelta(days=end_range)).date()  # Получаем только дату\n",
    "        end_of_day = (datetime.now() - timedelta(days=start_range)).date()  # Получаем только дату\n",
    "    \n",
    "    print(\"Локальные переменные:\", json.dumps(locals(), default=str, ensure_ascii=False, indent=4))\n",
    "\n",
    "    print('--------')\n",
    "    print('count of input items: ' + str(len(dataset_items)))\n",
    "    print('-----')\n",
    "\n",
    "    # Фильтруем только рилсы (type='Video'), которые попадают в целевые сутки (позавчера)\n",
    "    for item in dataset_items:\n",
    "        if 'type' in item and item['type'] == 'Video':\n",
    "            # Парсим время публикации\n",
    "            try:\n",
    "                post_time = datetime.strptime(item['timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\").date()  # Получаем только дату\n",
    "                print(post_time)\n",
    "            except ValueError:\n",
    "                print(f\"Ошибка при парсинге времени для элемента: {item}\")\n",
    "                continue  # Пропускаем элемент, если время не удалось распарсить\n",
    "\n",
    "            # Проверяем, входит ли пост в диапазон целевых дат\n",
    "            if start_of_day <= post_time <= end_of_day:\n",
    "                reelsData.append(item)\n",
    "    \n",
    "    # Печатаем отфильтрованные рилсы с их shortcode и timestamp\n",
    "    print(\"Отфильтрованные рилсы:\")\n",
    "    for reel in reelsData:\n",
    "        print(f\"Shortcode: {reel.get('shortCode')}, Timestamp: {reel.get('timestamp')}\")\n",
    "\n",
    "\n",
    "instagram_posts_scrapper(days=1, range_days=\"3-4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_win",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
