import gspread
from oauth2client.service_account import ServiceAccountCredentials
from googleapiclient.discovery import build
from dotenv import load_dotenv
import json, time

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()

# –î–æ—Å—Ç—É–ø –∫ –∫–ª—é—á—É

def get_table_data_as_json(account, list_name):
    try:
        print(f"Starting to collect data for {account['username']}")

        # Set up Google Sheets API credentials
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive.file",
            "https://www.googleapis.com/auth/drive"
        ]
        credentials = ServiceAccountCredentials.from_json_keyfile_name(
            'static/reelstranscription-a94a4b07252e.json', scope)
        client = gspread.authorize(credentials)

        # Open the Google Sheet
        google_sheet_url = f'https://docs.google.com/spreadsheets/d/{account["table_id"]}/edit?usp=sharing'
        sheet = client.open_by_url(google_sheet_url).worksheet(list_name)

        # Define the expected headers
        all_headers = ["username", "hashtag", "trigger", "viewsFilter", "likesFilter", "reels_count"]
        expected_headers = [header for header in all_headers if header in sheet.row_values(1)]  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤

        # Get all records with expected headers
        records = sheet.get_all_records(expected_headers=expected_headers)

        # Convert records to JSON format, filtering out rows with "off" triggers
        users_data = []

        for record in records:
            #print(record)
            if record.get("trigger") == "on":
                try:
                    if account['search_type'] == 'username':
                        user_data = {
                            "username": record.get("username"),
                            "viewsFilter":
                            int(record.get("viewsFilter", 0)),
                            "reels_count": int(record.get("reels_count", 0))
                        }
                    elif account['search_type'] == 'hashtag':
                        user_data = {
                            "hashtag": record.get("hashtag"),
                            "likesFilter":
                            int(record.get("likesFilter", 0)),
                            "reels_count": int(record.get("reels_count", 0))
                        }
                    users_data.append(user_data)
                except ValueError:
                    print(f"Skipping row with invalid data: {record}")
        return users_data
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ get_table_data_as_json: {e}")
        return []

def check_duplicates(apify_data, account, scraping_type, list_name):
    try:
        print(f"Starting to check for duplicates for {account['username']}")

        # Set up Google Sheets API credentials
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive.file",
            "https://www.googleapis.com/auth/drive"
        ]
        credentials = ServiceAccountCredentials.from_json_keyfile_name(
            'static/reelstranscription-a94a4b07252e.json', scope)
        client = gspread.authorize(credentials)

        # Open the Google Sheet
        google_sheet_url = f'https://docs.google.com/spreadsheets/d/{account["table_id"]}/edit?usp=sharing'
        sheet = client.open_by_url(google_sheet_url).worksheet(list_name)

        # Get all values from the third column (C) starting from the second row
        existing_urls = sheet.col_values(3)[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫

        # print(len(existing_urls))
        # print()
        # for url in existing_urls:
        #     print(url)
        apify_data_noDuplicates = []
        # Extract URLs from apify_data for comparison
        if scraping_type == 'instagram':
            apify_urls = {x.get('url', "") for x in apify_data}
            # Find duplicates
            duplicates = set(existing_urls) & apify_urls
            print(f'Count elements before check_duplicates: {len(apify_data)}')
            # Remove duplicates from apify_data
            apify_data_noDuplicates = [item for item in apify_data if item.get('url', "") not in duplicates]
            print(f'Count elements after check_duplicates: {len(apify_data_noDuplicates)}')
        elif scraping_type == 'tiktok':
            apify_urls = {x.get('postPage', "") for x in apify_data}
            # Find duplicates
            duplicates = set(existing_urls) & apify_urls
            print(f'Count elements before check_duplicates: {len(apify_data)}')
            # Remove duplicates from apify_data
            apify_data_noDuplicates = [item for item in apify_data if item.get('postPage', "") not in duplicates]
            print(f'Count elements after check_duplicates: {len(apify_data_noDuplicates)}')
            print("----------------")
            print("DUPLICATES")
            print(duplicates)
            print("----------------")


        return apify_data_noDuplicates
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ check_duplicates: {e}")
        return apify_data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏


# account_test = {
#         "id": 28,
#         "username": "saloapp",
#         "username_tg": "saloapp_test",
#         "table_id": "1EuPZzHvbq4I9PkkSNKGPO8Rsyg6HbISOujpk8ievzzI",
#         "topics" : "",
#         "subscription" : "1week",
#         "update_date" : "friday",
#         "language" : "english",
#         "search_type" : "hashtag"
#     }

# apify_data_test = [
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338401"},
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338402"},
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338403"},
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338404"},
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338405"},
#     {"postPage": "https://www.tiktok.com/@dee.yope/video/7466135328869338406"}
# ]

# apify_data_test = [
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338401"},
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338402"},
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338403"},
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338404"},
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338405"},
#     {"url": "https://www.tiktok.com/@dee.yope/video/7466135328869338406"}
# ]

# check_duplicates(apify_data_test, account_test, "tiktok", "TIKTOK")



# Example usage
#table_id = "1C9bpCjytr-J1kruMLzt0X-omxQW0s0MJHyOvDILjtYs"
#list_name = "Data"
#json_results = get_table_data_as_json(table_id, list_name)
#print(json.dumps(json_results, indent=1))



###########################
# 1. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
###########################

def col_name(idx_zero_based: int) -> str:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å 0-based (0,1,2...) –≤ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ (A,B,C...).
    0 -> A
    1 -> B
    25 -> Z
    26 -> AA
    27 -> AB
    ...
    """
    result = []
    i = idx_zero_based
    while True:
        i, r = divmod(i, 26)
        result.append(chr(r + ord('A')))
        if i == 0:
            break
        i -= 1
    return "".join(reversed(result))


def generate_original_script(item):
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 'original_script'.
    """
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞
    if (
        item.get("original_script", {}).get("hook", "") == '-' and 
        item.get("original_script", {}).get("content", "") == '-' and 
        item.get("original_script", {}).get("cta", "") == '-'
    ):
        return (f'''–ù–ï–¢ –¢–ï–ö–°–¢–ê

#CAPTION
{item.get("caption", "")}''')
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    return (
        f"""#HOOK
{item.get("original_script", {}).get("hook", "")}

#CONTENT
{item.get("original_script", {}).get("content", "")}

#CTA
{item.get("original_script", {}).get("cta", "")}

#CAPTION
{item.get("caption", "")}"""
    )


def generate_rewrited_script(item):
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ 'original_script'.
    """
    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å (song –∏ humor, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å)
    prefix = ""
    if item.get("song"):
        prefix += '''>>>–í–û–ó–ú–û–ñ–ù–û –ü–ï–°–ù–Ø<<<
'''

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞
    if (
        item.get("rewrited_script", {}).get("hook", "") == '-' and 
        item.get("rewrited_script", {}).get("content", "") == '-' and 
        item.get("rewrited_script", {}).get("cta", "") == '-'
    ):
        return (f'''–ù–ï–¢ –¢–ï–ö–°–¢–ê
        
#CAPTION
{item.get("rewrited_script", {}).get("caption", "")}''')
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    return (
        f"""{prefix}#HOOK
{item.get("rewrited_script", {}).get("hook", "")}

#CONTENT
{item.get("rewrited_script", {}).get("content", "")}

#CTA
{item.get("rewrited_script", {}).get("cta", "")}

#CAPTION
{item.get("rewrited_script", {}).get("caption", "")}"""
    )

###########################
# 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤
###########################
# –ó–¥–µ—Å—å –æ–±—ä—è–≤–ª—è–µ–º, –∫–∞–∫–∏–µ —Å—Ç–æ–ª–±—Ü—ã –∏ –≤ –∫–∞–∫–æ–º –ø–æ—Ä—è–¥–∫–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å
# –¥–ª—è (scheme, scraping_type). 
# –ö–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å:
#   "name"       - –ª—é–±–æ–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Å—Ç–æ–ª–±—Ü–∞
#   "value_func" - —Ñ—É–Ω–∫—Ü–∏—è (item, row_number, i2excel, name2idx), 
#                  –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —è—á–µ–π–∫–∏.
#
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–Ω—É—Ç—Ä–∏ value_func:
#  - item       : –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –∏–∑ json_results
#  - row_number : —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ new_number (–Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ ¬´–ª–æ–≥–∏—á–µ—Å–∫–∏–π¬ª)
#  - i2excel(i) : —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –≤–µ—Ä–Ω—ë—Ç –±—É–∫–≤–µ–Ω–Ω—ã–π –∫–æ–¥ —Å—Ç–æ–ª–±—Ü–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É
#  - name2idx   : —Å–ª–æ–≤–∞—Ä—å { "–∏–º—è_—Å—Ç–æ–ª–±—Ü–∞" -> –∏–Ω–¥–µ–∫—Å }, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ
#                 —Å–æ—Å–ª–∞—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥–∏–µ –∫–æ–ª–æ–Ω–∫–∏



COLUMNS_CONFIG = {
    (0, "instagram"): [
        {
            "name": "num",
            "value_func": lambda item, row_n, i2excel, name2idx: row_n
        },
        {
            "name": "userlink",
            "value_func": lambda item, row_n, i2excel, name2idx: f'=HYPERLINK("{item.get("account_url", "")}", "{item.get("username", "")}")'
        },
        {
            "name": "url",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("url", "")
        },
        {
            "name": "timestamp",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("timestamp", "")
        },
        {
            "name": "topic",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("topic", "")
        },
        {
            "name": "theme",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("theme", "")
        },
        {
            "name": "hook",
            "value_func": lambda item, row_n, i2excel, name2idx: item["original_script"].get("hook", "")
        },
        {
            "name": "caption",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("caption", "")
        },
        {
            "name": "len_caption",
            "value_func": lambda item, row_n, i2excel, name2idx:
                f'=len(INDIRECT("{col_name(name2idx["caption"])}"&ROW()))'
        },
        {
            "name": "followers",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("followersCount", "")
        },
        {
            "name": "views",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("videoPlayCount", "")
        },
        {
            "name": "er_followers-views",
            "value_func": lambda item, row_n, i2excel, name2idx: ( f'=TO_PERCENT({item.get("er_followers", "-")})')
        },
        {
            "name": "likes",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("likesCount", "")
        },
        {
            "name": "comments",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("commentsCount", "")
        },
        {
            "name": "er_commlike",
            "value_func": lambda item, row_n, i2excel, name2idx: (
                f'=TO_PERCENT({item.get("er_commlike", "")})'
                if item.get("er_commlike") != ""
                else ""
            )
        },
        {
            "name": "virus_detector",
            "value_func": lambda item, row_n, i2excel, name2idx: (
                f'=IF(COUNT(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW()))) = 1, 0, (INDIRECT("{col_name(name2idx["views"])}"&ROW()) - MEDIAN(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW())))) / (2 * (STDEV(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW())))  + 0.0000000001)))'
            )
        },
        {
            "name": "shares",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("shareCount", "")
        },
        {
            "name": "ER_shares_views",
            "value_func": lambda item, row_n, i2excel, name2idx: ( f'=TO_PERCENT({item.get("er_shares", "")})')
        },
        {
            "name": "duration",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("videoDuration", "")
        },
        {
            "name": "virus_status",
            "value_func": lambda item, row_n, i2excel, name2idx: (
                f'=IF(COUNTIF({col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])}, INDIRECT("{col_name(name2idx["userlink"])}"&ROW()))<4, "NO DATA", IF(INDIRECT("{col_name(name2idx["virus_detector"])}"&ROW())<-0.1, "LOW", IF(INDIRECT("{col_name(name2idx["virus_detector"])}"&ROW())<= 0.1, "AVERAGE", IF(INDIRECT("{col_name(name2idx["virus_detector"])}"&ROW())<=0.4, "GOOD", IF(INDIRECT("{col_name(name2idx["virus_detector"])}"&ROW())<=0.8, "BEST", "VIRUS")))))'
                )
        },
        {
            "name": "engagement_status",
            "value_func": lambda item, row_n, i2excel, name2idx: (
                f'=IF(AND(INDIRECT("{col_name(name2idx["er_commlike"])}"&ROW())<0.02,INDIRECT("{col_name(name2idx["ER_shares_views"])}"&ROW())<0.005), "LOW ER", IF(AND(INDIRECT("{col_name(name2idx["er_commlike"])}"&ROW())<=0.04,INDIRECT("{col_name(name2idx["ER_shares_views"])}"&ROW())<=0.01), "AVERAGE ER", "BEST ER"))'
                )
        },
        {
            "name": "original_script",
            "value_func": lambda item, row_n, i2excel, name2idx: generate_original_script(item)
        },
        {
            "name": "rewrited_script",
            "value_func": lambda item, row_n, i2excel, name2idx: generate_rewrited_script(item)
        },
        {
            "name": "musicInfo",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("musicInfo", "")
        }
    ],

    (0, "tiktok"): [
        # –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ, –Ω–æ –Ω—É–∂–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è TikTok
        {
            "name": "num",
            "value_func": lambda item, row_n, i2excel, name2idx: row_n
        },
        {
            "name": "userlink",
            "value_func": lambda item, row_n, i2excel, name2idx: f'=HYPERLINK("{item.get("account_url", "")}", "{item.get("username", "")}")'
        },
        {
            "name": "url",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("url", "")
        },
        {
            "name": "timestamp",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("timestamp", "")
        },
        {
            "name": "topic",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("topic", "")
        },
        {
            "name": "theme",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("theme", "")
        },
        {
            "name": "empty",
            "value_func": lambda item, row_n, i2excel, name2idx: ""
        },
        {
            "name": "caption",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("caption", "")
        },
        {
            "name": "len_caption",
            "value_func": lambda item, row_n, i2excel, name2idx:
                f'=len(INDIRECT("{col_name(name2idx["caption"])}"&ROW()))'
        },
        {
            "name": "followers",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("followersCount", "")
        },
        {
            "name": "views",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("videoPlayCount", "")
        },
        {
            "name": "er_followers",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("er_followers", "")
        },
        {
            "name": "likes",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("likesCount", "")
        },
        {
            "name": "comments",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("commentsCount", "")
        },
        {
            "name": "shares",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("shareCount", "")
        },
        {
            "name": "saves",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("collectCount", "")
        },
        {
            "name": "er_all",
            "value_func": lambda item, row_n, i2excel, name2idx: (f'=TO_PERCENT({item.get("er_all", "-")})')
        },
        {
            "name": "er_shares",
            "value_func": lambda item, row_n, i2excel, name2idx: ( f'=TO_PERCENT({item.get("er_shares", "-")})')
        },
        {
            "name": "virus_detector",
            "value_func": lambda item, row_n, i2excel, name2idx: (
                f'=IF(COUNT(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW()))) = 1, 0, (INDIRECT("{col_name(name2idx["views"])}"&ROW()) - MEDIAN(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW())))) / (2 * (STDEV(FILTER({col_name(name2idx["views"])}:{col_name(name2idx["views"])}, {col_name(name2idx["userlink"])}:{col_name(name2idx["userlink"])} = INDIRECT("{col_name(name2idx["userlink"])}"&ROW())))  + 0.0000000001)))'
            )
        },
        {
            "name": "duration",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("videoDuration", "")
        },
        {
            "name": "original_script",
            "value_func": lambda item, row_n, i2excel, name2idx: generate_original_script(item)
        },
        {
            "name": "rewrited_script",
            "value_func": lambda item, row_n, i2excel, name2idx: generate_rewrited_script(item)
        },
        {
            "name": "musicInfo",
            "value_func": lambda item, row_n, i2excel, name2idx: item.get("musicInfo", "")
        }
    ],

    (2, "instagram"): [
        # –ü—Ä–∏–º–µ—Ä –¥–ª—è scheme=2
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø—Ä–æ–ø–∏—Å–∞—Ç—å –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        # ...
    ],
}

############################
# 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫–∏
############################



def generate_row_data(item, row_number, scheme, scraping_type):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π —è—á–µ–µ–∫ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ 'item' –∏ 'row_number',
    –≤ —Ç–æ–º –ø–æ—Ä—è–¥–∫–µ, –≤ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω–∏ –æ–ø–∏—Å–∞–Ω—ã –≤ COLUMNS_CONFIG[(scheme, scraping_type)].
    """
    columns = COLUMNS_CONFIG.get((scheme, scraping_type), [])
    # name2idx: { "–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å—Ç–æ–ª–±—Ü–∞" -> –∏–Ω–¥–µ–∫—Å_–≤_—ç—Ç–æ–º_—Å–ø–∏—Å–∫–µ }
    name2idx = {}
    for i, col_def in enumerate(columns):
        name2idx[col_def["name"]] = i

    row_values = []
    for i, col_def in enumerate(columns):
        val = col_def["value_func"](item, row_number, col_name, name2idx)
        row_values.append(val)
    return row_values


############################
# 4. –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
############################

def append_data_to_google_sheet(json_results, table_id, list_name, scheme=0, scraping_type=None):
    try:
        print('Starting collect data for google sheet')
        # --- –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è ---
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive.file",
            "https://www.googleapis.com/auth/drive"
        ]
        credentials = ServiceAccountCredentials.from_json_keyfile_name(
            'static/reelstranscription-a94a4b07252e.json', scope)
        client = gspread.authorize(credentials)

        # --- –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É ---
        google_sheet_url = f'https://docs.google.com/spreadsheets/d/{table_id}/edit?usp=sharing'
        sheet = client.open_by_url(google_sheet_url).worksheet(list_name)
        sheet_id = sheet.id

        # --- –°—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –≤ A3 (3-—è —Å—Ç—Ä–æ–∫–∞, 1-–π —Å—Ç–æ–ª–±–µ—Ü) ---
        cell_value = sheet.cell(3, 1).value
        if cell_value is None or not cell_value.isdigit():
            new_number = 1
        else:
            new_number = int(cell_value) + 1

        # --- –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏ ---
        rows_to_insert = []
        for i, item in enumerate(json_results):
            row_to_insert = generate_row_data(item, new_number, scheme, scraping_type)
            rows_to_insert.append(row_to_insert)
            new_number += 1
            print(f'–ó–∞–ø–∏—Å—å {i + 1} –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏')

        # --- –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Ä–∞–∑—É –≤—Å–µ –¥–∞–Ω–Ω—ã–µ (—Ä–µ–≤–µ—Ä—Å–æ–º, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ) ---
        rows_to_insert.reverse()
        #sheet.insert_rows(rows_to_insert, row=3, value_input_option='USER_ENTERED')
        #update existing filters

        sheet.insert_rows(rows_to_insert, row=3, value_input_option='USER_ENTERED')
        print("‚úÖ –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞.")
        # try:
        #     #FILTER

        #     # 3Ô∏è‚É£ –°—á–∏—Ç—ã–≤–∞–µ–º —Ç–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã
        #     service = build('sheets', 'v4', credentials=credentials)
        #     spreadsheet = service.spreadsheets().get(spreadsheetId=table_id).execute()
        #     sheet_info = next((s for s in spreadsheet['sheets'] if s['properties']['sheetId'] == sheet_id), None)

        #     if not sheet_info or "basicFilter" not in sheet_info:
        #         print("‚ö†Ô∏è –ë–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.")

        #     existing_filter = sheet_info["basicFilter"]
        #     print("üéØ –¢–µ–∫—É—â–∏–µ —Ñ–∏–ª—å—Ç—Ä—ã –ø–µ—Ä–µ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º:")
        #     print(json.dumps(existing_filter, indent=4, ensure_ascii=False))

        #     # 4Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä—É–µ–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
        #     criteria_columns = list(existing_filter.get("criteria", {}).keys())
        #     column_value_map = {}

        #     # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –¥–ª—è —ç—Ç–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
        #     ranges = [f"'TEST_FILTER'!{chr(65 + int(col))}2:{chr(65 + int(col))}" for col in criteria_columns]
        #     result = service.spreadsheets().values().batchGet(
        #         spreadsheetId=table_id,
        #         ranges=ranges
        #     ).execute()

        #     # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        #     for idx, col in enumerate(criteria_columns):
        #         column_values = result.get("valueRanges", [])[idx].get("values", [])
        #         # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–≤–æ–¥
        #         unique_values = {val[0] for val in column_values if val}
        #         column_value_map[int(col)] = unique_values
        #         #print(f"üìä –ö–æ–ª–æ–Ω–∫–∞ {col}: {list(unique_values)[:5]}... (–ø–æ–∫–∞–∑–∞–Ω–æ 5 –∏–∑ {len(unique_values)})")

        #     # 5Ô∏è‚É£ –û—Ç–∫–ª—é—á–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        #     service.spreadsheets().batchUpdate(
        #         spreadsheetId=table_id,
        #         body={"requests": [{"clearBasicFilter": {"sheetId": sheet_id}}]}
        #     ).execute()
        #     #print("üö® –§–∏–ª—å—Ç—Ä—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

        #     # 6Ô∏è‚É£ –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
        #     header_row = sheet.row_values(1)
        #     new_row = ["" for _ in range(len(header_row))]
        #     try:
        #         virus_index = header_row.index("–í–∏—Ä—É—Å–Ω–æ—Å—Ç—å")
        #         engagement_index = header_row.index("–í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å")
        #         new_row[virus_index] = "NO DATA"
        #         new_row[engagement_index] = "LOW ER"
        #     except ValueError:
        #         print("‚ö†Ô∏è –°—Ç–æ–ª–±—Ü—ã '–í–∏—Ä—É—Å–Ω–æ—Å—Ç—å' –∏–ª–∏ '–í–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç—å' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")




        #     sheet.insert_rows(rows_to_insert, row=3, value_input_option='USER_ENTERED')
        #     print("‚úÖ –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞.")




        #     # 7Ô∏è‚É£ –û–±–Ω–æ–≤–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Ñ–∏–ª—å—Ç—Ä–∞
        #     existing_filter["range"]["endRowIndex"] = sheet.row_count

        #     # 8Ô∏è‚É£ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∫—Ä—ã—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        #     if "criteria" in existing_filter:
        #         for col_idx, criteria in existing_filter["criteria"].items():
        #             if "hiddenValues" in criteria:
        #                 current_hidden = set(criteria["hiddenValues"])
        #                 possible_values = column_value_map.get(int(col_idx), set())
        #                 # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å–∫—Ä—ã—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        #                 updated_hidden = current_hidden.intersection(possible_values)
        #                 existing_filter["criteria"][col_idx]["hiddenValues"] = list(updated_hidden)

        #     # 9Ô∏è‚É£ –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        #     service.spreadsheets().batchUpdate(
        #         spreadsheetId=table_id,
        #         body={"requests": [{"setBasicFilter": {"filter": existing_filter}}]}
        #     ).execute()
        #     print("üîÑ –§–∏–ª—å—Ç—Ä—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã —Å –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–æ–º.")
        # except Exception as e:
        #     print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –≤ ggl: {e}")

            
        print(f"–í—Å–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ append_data_to_google_sheet –≤ ggl: {e}")

    print("Done!")



############################
# SCRAPE NUMBER OF REELS IN TABLES
############################


def get_video_processed_number(account):
    try:
        print(f"----Starting to collect data for {account['username']}")

        # Set up Google Sheets API credentials
        scope = [
            "https://spreadsheets.google.com/feeds",
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive.file",
            "https://www.googleapis.com/auth/drive"
        ]
        credentials = ServiceAccountCredentials.from_json_keyfile_name(
            'static/reelstranscription-a94a4b07252e.json', scope)
        client = gspread.authorize(credentials)

        # Open the Google Sheet
        google_sheet_url = f'https://docs.google.com/spreadsheets/d/{account["table_id"]}/edit?usp=sharing'
        # Open the Google Sheets for both INSTAGRAM and TIKTOK
        instagram_sheet = client.open_by_url(google_sheet_url).worksheet('INSTAGRAM')
        tiktok_sheet = client.open_by_url(google_sheet_url).worksheet('TIKTOK')

        # Read the value from cell A3 for both sheets
        instagram_a3_value = instagram_sheet.cell(3, 1).value
        tiktok_a3_value = tiktok_sheet.cell(3, 1).value

        print(f"INSTAGRAM A3 Value: {instagram_a3_value}")
        print(f"TIKTOK A3 Value: {tiktok_a3_value}")
        return instagram_a3_value, tiktok_a3_value
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ get_table_data_as_json: {e}")
        return None

def sum_a3_values():

    with open("db/main/db.json", "r", encoding="utf-8") as file:
        table_list = json.load(file)
    
    total_instagram_a3 = 0
    total_tiktok_a3 = 0

    for account in table_list["accounts"]:
        try:
            instagram_a3_value, tiktok_a3_value = get_video_processed_number(account)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ None –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏—Ö –≤ —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞
            if instagram_a3_value is not None:
                total_instagram_a3 += int(instagram_a3_value)
            if tiktok_a3_value is not None:
                total_tiktok_a3 += int(tiktok_a3_value)
            time.sleep(2)
            print(f'-----account {account["username"]} scrapped')
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ for account in table_list: {e}")
            return None

    print(f"Total INSTAGRAM A3 Value: {total_instagram_a3}")
    print(f"Total TIKTOK A3 Value: {total_tiktok_a3}")
    sum = total_instagram_a3+total_tiktok_a3
    print(f"Total SUM: {sum}")
    return sum


#sum_a3_values()



############################
# DEBUG
############################
'''
with open("db/22/damir_result_20250104_151517.json", "r", encoding="utf-8") as file:
    results = json.load(file)
append_data_to_google_sheet(results, "1uXEWHBW2aNChgtR9mB4JOV-fpTZS83i_oMT_Ar-vtJo", 'TIKTOK', scraping_type="tiktok")
'''


